{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f202bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/04 01:29:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/02/04 01:29:16 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,split,count, size, explode, length, when\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"arxivCategoryEDA\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.json(\"../../../data/arxiv-metadata-oai-snapshot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a72fa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:================================================>       (33 + 5) / 38]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+----------+------------------+\n",
      "|total_abstracts|min_length|max_length|        avg_length|\n",
      "+---------------+----------+----------+------------------+\n",
      "|          19947|        87|      2231|1324.6611520529402|\n",
      "+---------------+----------+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, split, count, length, min, max, avg, \n",
    "    array, lit, to_date, size, array_intersect\n",
    ")\n",
    "\n",
    "# 1. Configuration: We require BOTH of these\n",
    "REQUIRED_CATEGORIES = [\"cs.AI\", \"cs.LG\"]\n",
    "START_DATE = \"2025-01-01\"\n",
    "\n",
    "# 2. Create the array column literal\n",
    "req_cats_col = array([lit(c) for c in REQUIRED_CATEGORIES])\n",
    "\n",
    "# 3. Apply Filtering Logic\n",
    "#    We use size() to convert the array result into a number we can compare.\n",
    "filtered_df = df.withColumn(\"cat_array\", split(col(\"categories\"), \" \")) \\\n",
    "    .filter(\n",
    "        # LOGIC: The intersection must contain exactly as many items as our required list.\n",
    "        # If intersection size == 2, it means BOTH cs.AI and cs.LG were found.\n",
    "        (size(array_intersect(col(\"cat_array\"), req_cats_col)) == size(req_cats_col)) & \n",
    "        (to_date(col(\"update_date\")) >= lit(START_DATE))\n",
    "    )\n",
    "\n",
    "# 4. Calculate Statistics\n",
    "stats_df = filtered_df.select(length(col(\"abstract\")).alias(\"abs_len\")) \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_abstracts\"),\n",
    "        min(\"abs_len\").alias(\"min_length\"),\n",
    "        max(\"abs_len\").alias(\"max_length\"),\n",
    "        avg(\"abs_len\").alias(\"avg_length\")\n",
    "    )\n",
    "\n",
    "stats_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4a96f",
   "metadata": {},
   "source": [
    "Top 10 rows of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea44fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       categories|\n",
      "+-----------------+\n",
      "|           hep-ph|\n",
      "|    math.CO cs.CG|\n",
      "|   physics.gen-ph|\n",
      "|          math.CO|\n",
      "|  math.CA math.FA|\n",
      "|cond-mat.mes-hall|\n",
      "|            gr-qc|\n",
      "|cond-mat.mtrl-sci|\n",
      "|         astro-ph|\n",
      "|          math.CO|\n",
      "|  math.NT math.AG|\n",
      "|          math.NT|\n",
      "|          math.NT|\n",
      "|  math.CA math.AT|\n",
      "|           hep-th|\n",
      "|           hep-ph|\n",
      "|         astro-ph|\n",
      "|           hep-th|\n",
      "|  math.PR math.AG|\n",
      "|           hep-ex|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"categories\"]).\\\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad48169",
   "metadata": {},
   "source": [
    "Explode Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40636301",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df.withColumn(\"category\", explode(split(col(\"categories\"), \" \")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833f63e",
   "metadata": {},
   "source": [
    "Category Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e1d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:===================================================>     (34 + 4) / 38]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|          category| count|\n",
      "+------------------+------+\n",
      "|             cs.LG|242508|\n",
      "|            hep-ph|191810|\n",
      "|            hep-th|177961|\n",
      "|             cs.CV|173824|\n",
      "|          quant-ph|170398|\n",
      "|             cs.AI|151883|\n",
      "|             gr-qc|117690|\n",
      "|          astro-ph|105380|\n",
      "| cond-mat.mtrl-sci|104154|\n",
      "| cond-mat.mes-hall| 98338|\n",
      "|             cs.CL| 97377|\n",
      "|           math.MP| 86880|\n",
      "|           math-ph| 86880|\n",
      "|   cond-mat.str-el| 80258|\n",
      "|cond-mat.stat-mech| 79055|\n",
      "|           math.CO| 74707|\n",
      "|       astro-ph.CO| 74381|\n",
      "|           stat.ML| 74330|\n",
      "|       astro-ph.GA| 73745|\n",
      "|           math.AP| 70446|\n",
      "+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cat_freq = cat_df.groupBy(\"category\").count().orderBy(col(\"count\").desc())\n",
    "cat_freq.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92923139",
   "metadata": {},
   "source": [
    "Long Tail Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_freq.filter(col(\"count\") < 100).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c3f92",
   "metadata": {},
   "source": [
    "Multi-label Count Per Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:================================================>       (33 + 5) / 38]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|num_labels|  count|\n",
      "+----------+-------+\n",
      "|         1|1514466|\n",
      "|         2| 868892|\n",
      "|         3| 352262|\n",
      "|         4| 113661|\n",
      "|         5|  32690|\n",
      "|         6|   7126|\n",
      "|         7|   1013|\n",
      "|         8|    171|\n",
      "|         9|     34|\n",
      "|        10|     14|\n",
      "|        11|      2|\n",
      "|        13|      1|\n",
      "+----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"num_labels\", size(split(col(\"categories\"), \" \"))) \\\n",
    "  .groupBy(\"num_labels\").count().orderBy(\"num_labels\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472107bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2890321"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropDuplicates()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd986db",
   "metadata": {},
   "source": [
    "Extract first category (single-label baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c47500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    \"primary_category\",\n",
    "    split(col(\"categories\"), \" \").getItem(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b4c73a",
   "metadata": {},
   "source": [
    "Extract prefix before dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373e7cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+----------------+---------------+\n",
      "|            abstract|             authors|      authors_parsed|     categories|            comments|                 doi|       id|         journal-ref|             license|       report-no|         submitter|               title|update_date|            versions|primary_category|category_prefix|\n",
      "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+----------------+---------------+\n",
      "|  A fully differe...|C. Bal\\'azs, E. L...|[[Balázs, C., ], ...|         hep-ph|37 pages, 15 figu...|10.1103/PhysRevD....|0704.0001|Phys.Rev.D76:0130...|                NULL|ANL-HEP-PR-07-12|    Pavel Nadolsky|Calculation of pr...| 2008-11-26|[{Mon, 2 Apr 2007...|          hep-ph|         hep-ph|\n",
      "|  We describe a n...|Ileana Streinu an...|[[Streinu, Ileana...|  math.CO cs.CG|To appear in Grap...|                NULL|0704.0002|                NULL|http://arxiv.org/...|            NULL|      Louis Theran|Sparsity-certifyi...| 2008-12-13|[{Sat, 31 Mar 200...|         math.CO|           math|\n",
      "|  The evolution o...|         Hongjun Pan|  [[Pan, Hongjun, ]]| physics.gen-ph| 23 pages, 3 figures|                NULL|0704.0003|                NULL|                NULL|            NULL|       Hongjun Pan|The evolution of ...| 2008-01-13|[{Sun, 1 Apr 2007...|  physics.gen-ph|        physics|\n",
      "|  We show that a ...|        David Callan| [[Callan, David, ]]|        math.CO|            11 pages|                NULL|0704.0004|                NULL|                NULL|            NULL|      David Callan|A determinant of ...| 2007-05-23|[{Sat, 31 Mar 200...|         math.CO|           math|\n",
      "|  In this paper w...|Wael Abu-Shammala...|[[Abu-Shammala, W...|math.CA math.FA|                NULL|                NULL|0704.0005|Illinois J. Math....|                NULL|            NULL|Alberto Torchinsky|From dyadic $\\Lam...| 2013-10-15|[{Mon, 2 Apr 2007...|         math.CA|           math|\n",
      "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+---------+--------------------+--------------------+----------------+------------------+--------------------+-----------+--------------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    \"category_prefix\",\n",
    "    split(col(\"primary_category\"), \"\\.\").getItem(0)\n",
    ")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check if there are chemistry papers\n",
    "df.filter(col(\"category_prefix\") == \"chem\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f3c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"final_category\",\n",
    "    when(col(\"category_prefix\") == \"cs\", \"cs\")\n",
    "    .when(col(\"category_prefix\") == \"math\", \"math\")\n",
    "    .when(col(\"category_prefix\") == \"physics\", \"physics\")\n",
    "    .when(col(\"category_prefix\") == \"stat\", \"stat\")\n",
    "    .when(col(\"category_prefix\") == \"q-bio\", \"bio\")\n",
    "    .when(col(\"category_prefix\") == \"econ\", \"econ\")\n",
    "    .when(col(\"category_prefix\") == \"eess\", \"engineering\")\n",
    "    .when(col(\"category_prefix\") == \"chem\", \"chemistry\")\n",
    "    .otherwise(\"other\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edfb16e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------+\n",
      "|       id|               title|final_category|\n",
      "+---------+--------------------+--------------+\n",
      "|0704.0001|Calculation of pr...|         other|\n",
      "|0704.0002|Sparsity-certifyi...|          math|\n",
      "|0704.0003|The evolution of ...|       physics|\n",
      "|0704.0004|A determinant of ...|          math|\n",
      "|0704.0005|From dyadic $\\Lam...|          math|\n",
      "+---------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['id','title','final_category']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97566d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:======================================================> (49 + 1) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|final_category|count  |\n",
      "+--------------+-------+\n",
      "|other         |1273379|\n",
      "|cs            |691231 |\n",
      "|math          |556370 |\n",
      "|physics       |201469 |\n",
      "|engineering   |66850  |\n",
      "|stat          |58160  |\n",
      "|bio           |32717  |\n",
      "|econ          |10145  |\n",
      "+--------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"final_category\") \\\n",
    "  .count() \\\n",
    "  .orderBy(col(\"count\").desc()) \\\n",
    "  .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6d389",
   "metadata": {},
   "source": [
    "PERCENTAGE DISTRIBUTION OF FINAL CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c7186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:======================================================> (49 + 1) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+-------------------+\n",
      "|final_category|count  |percentage         |\n",
      "+--------------+-------+-------------------+\n",
      "|other         |1273379|44.05666360241648  |\n",
      "|cs            |691231 |23.91537133764727  |\n",
      "|math          |556370 |19.24941900916888  |\n",
      "|physics       |201469 |6.970471445905144  |\n",
      "|engineering   |66850  |2.312891889862752  |\n",
      "|stat          |58160  |2.0122332432971977 |\n",
      "|bio           |32717  |1.131950395821087  |\n",
      "|econ          |10145  |0.35099907588119106|\n",
      "+--------------+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "total = df.count()\n",
    "\n",
    "dist_df = df.groupBy(\"final_category\").count() \\\n",
    "    .withColumn(\"percentage\", col(\"count\") / total * 100) \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "dist_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ac3d6",
   "metadata": {},
   "source": [
    "See percentage distribution inside other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabe4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:===================================>                    (16 + 9) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+---------------------+\n",
      "|category_prefix|count |percent              |\n",
      "+---------------+------+---------------------+\n",
      "|cond-mat       |338294|26.56663884043949    |\n",
      "|astro-ph       |326072|25.6068303309541     |\n",
      "|hep-ph         |139714|10.971910169713809   |\n",
      "|quant-ph       |124246|9.75718933640338     |\n",
      "|hep-th         |110761|8.698195902398265    |\n",
      "|gr-qc          |69205 |5.434752732689954    |\n",
      "|nucl-th        |34987 |2.7475716185047814   |\n",
      "|math-ph        |33378 |2.6212148936019832   |\n",
      "|hep-ex         |24463 |1.9211091120554054   |\n",
      "|nlin           |20283 |1.5928486334390626   |\n",
      "|hep-lat        |18750 |1.4724602808747436   |\n",
      "|q-fin          |12827 |1.0073198945482846   |\n",
      "|nucl-ex        |12196 |0.9577666978959132   |\n",
      "|chao-dyn       |1770  |0.1390002505145758   |\n",
      "|alg-geom       |1209  |0.09494423891080346  |\n",
      "|q-alg          |1177  |0.0924312400314439   |\n",
      "|cmp-lg         |894   |0.07020690619210777  |\n",
      "|solv-int       |844   |0.06628034544310846  |\n",
      "|dg-ga          |562   |0.044134542818752315 |\n",
      "|patt-sol       |452   |0.03549610917095382  |\n",
      "|funct-an       |320   |0.025129988793595622 |\n",
      "|adap-org       |306   |0.024030551783875812 |\n",
      "|mtrl-th        |165   |0.012957650471697743 |\n",
      "|comp-gas       |140   |0.010994370097198084 |\n",
      "|chem-ph        |129   |0.010130526732418235 |\n",
      "|supr-con       |69    |0.0054186538336190564|\n",
      "|atom-ph        |68    |0.00534012261863907  |\n",
      "|acc-phys       |46    |0.0036124358890793707|\n",
      "|plasm-ph       |28    |0.002198874019439617 |\n",
      "|ao-sci         |13    |0.0010209057947398222|\n",
      "|bayes-an       |11    |8.638433647798495E-4 |\n",
      "+---------------+------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as spark_sum\n",
    "\n",
    "other_df = df.filter(col(\"final_category\") == \"other\")\n",
    "\n",
    "total_other = other_df.count()\n",
    "\n",
    "other_dist = (\n",
    "    other_df.groupBy(\"category_prefix\")\n",
    "    .count()\n",
    "    .withColumn(\"percent\", col(\"count\") * 100 / total_other)\n",
    "    .orderBy(col(\"percent\").desc())\n",
    ")\n",
    "\n",
    "other_dist.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43603bb",
   "metadata": {},
   "source": [
    "DROP UNNEEDED CATEGORIES AND CATEGORY-PREFIX COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71bbfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"categories\", \"category_prefix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4584c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- authors_parsed: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- journal-ref: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- report-no: string (nullable = true)\n",
      " |-- submitter: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      " |-- versions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- created: string (nullable = true)\n",
      " |    |    |-- version: string (nullable = true)\n",
      " |-- primary_category: string (nullable = true)\n",
      " |-- final_category: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b08b3",
   "metadata": {},
   "source": [
    "DATASET FOR TABLEAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52add41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,explode_outer,year,to_timestamp,concat_ws\n",
    "\n",
    "df_small = (\n",
    "    df\n",
    "    .select(\"id\", \"final_category\", \"authors_parsed\", \"versions\", \"submitter\",\"update_date\")\n",
    "    .filter(col(\"submitter\").isNotNull())\n",
    "    .limit(60000)   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbffdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = (\n",
    "    df_small\n",
    "    .withColumn(\"author\", explode_outer(\"authors_parsed\"))\\\n",
    "    .withColumn(\"version\", explode_outer(\"versions\"))\\\n",
    "    .withColumn(\"last_name\", col(\"author\")[0]) \n",
    "    .withColumn(\"first_name\", col(\"author\")[1])\n",
    "    .withColumn(\"version_no\", col(\"version.version\"))\n",
    "    .withColumn(\"version_date\", col(\"version.created\"))\n",
    ")\n",
    "\n",
    "df_exploded = df_exploded.withColumn(\n",
    "    \"author_name\",\n",
    "    concat_ws(\" \", col(\"first_name\"), col(\"last_name\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d74aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=====================================================>  (48 + 2) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+--------------------+-----------------+-----------+--------------------+--------------------+---------+------------+----------+--------------------+--------------------+\n",
      "|        id|final_category|      authors_parsed|            versions|        submitter|update_date|              author|             version|last_name|  first_name|version_no|        version_date|         author_name|\n",
      "+----------+--------------+--------------------+--------------------+-----------------+-----------+--------------------+--------------------+---------+------------+----------+--------------------+--------------------+\n",
      "|2508.00233|            cs|[[Markant, Dougla...|[{Fri, 01 Aug 202...|       Subham Sah| 2025-08-04|[Markant, Douglas, ]|{Fri, 01 Aug 2025...|  Markant|     Douglas|        v1|Fri, 01 Aug 2025 ...|     Douglas Markant|\n",
      "|2508.00233|            cs|[[Markant, Dougla...|[{Fri, 01 Aug 202...|       Subham Sah| 2025-08-04|     [Sah, Subham, ]|{Fri, 01 Aug 2025...|      Sah|      Subham|        v1|Fri, 01 Aug 2025 ...|          Subham Sah|\n",
      "|2508.00233|            cs|[[Markant, Dougla...|[{Fri, 01 Aug 202...|       Subham Sah| 2025-08-04|[Karduni, Alireza, ]|{Fri, 01 Aug 2025...|  Karduni|     Alireza|        v1|Fri, 01 Aug 2025 ...|     Alireza Karduni|\n",
      "|2508.00233|            cs|[[Markant, Dougla...|[{Fri, 01 Aug 202...|       Subham Sah| 2025-08-04|    [Rogha, Milad, ]|{Fri, 01 Aug 2025...|    Rogha|       Milad|        v1|Fri, 01 Aug 2025 ...|         Milad Rogha|\n",
      "|2508.00233|            cs|[[Markant, Dougla...|[{Fri, 01 Aug 202...|       Subham Sah| 2025-08-04|        [Thai, My, ]|{Fri, 01 Aug 2025...|     Thai|          My|        v1|Fri, 01 Aug 2025 ...|             My Thai|\n",
      "|2508.00233|            cs|[[Markant, Dougla...|[{Fri, 01 Aug 202...|       Subham Sah| 2025-08-04|     [Dou, Wenwen, ]|{Fri, 01 Aug 2025...|      Dou|      Wenwen|        v1|Fri, 01 Aug 2025 ...|          Wenwen Dou|\n",
      "|2508.00250|         other|[[Martinez, Victo...|[{Fri, 01 Aug 202...|     Vidya Manian| 2025-08-04|[Martinez, Victor...|{Fri, 01 Aug 2025...| Martinez|   Victor D.|        v1|Fri, 01 Aug 2025 ...|  Victor D. Martinez|\n",
      "|2508.00250|         other|[[Martinez, Victo...|[{Fri, 01 Aug 202...|     Vidya Manian| 2025-08-04|   [Manian, Vidya, ]|{Fri, 01 Aug 2025...|   Manian|       Vidya|        v1|Fri, 01 Aug 2025 ...|        Vidya Manian|\n",
      "|2508.00250|         other|[[Martinez, Victo...|[{Fri, 01 Aug 202...|     Vidya Manian| 2025-08-04|   [Malik, Sudhir, ]|{Fri, 01 Aug 2025...|    Malik|      Sudhir|        v1|Fri, 01 Aug 2025 ...|        Sudhir Malik|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|[Collins, Katheri...|{Fri, 01 Aug 2025...|  Collins|Katherine M.|        v1|Fri, 01 Aug 2025 ...|Katherine M. Collins|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|    [Todd, Graham, ]|{Fri, 01 Aug 2025...|     Todd|      Graham|        v1|Fri, 01 Aug 2025 ...|         Graham Todd|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|[Zhang, Cedegao E...|{Fri, 01 Aug 2025...|    Zhang|  Cedegao E.|        v1|Fri, 01 Aug 2025 ...|    Cedegao E. Zhang|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|  [Weller, Adrian, ]|{Fri, 01 Aug 2025...|   Weller|      Adrian|        v1|Fri, 01 Aug 2025 ...|       Adrian Weller|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|[Togelius, Julian, ]|{Fri, 01 Aug 2025...| Togelius|      Julian|        v1|Fri, 01 Aug 2025 ...|     Julian Togelius|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|      [Chu, Junyi, ]|{Fri, 01 Aug 2025...|      Chu|       Junyi|        v1|Fri, 01 Aug 2025 ...|           Junyi Chu|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|    [Wong, Lionel, ]|{Fri, 01 Aug 2025...|     Wong|      Lionel|        v1|Fri, 01 Aug 2025 ...|         Lionel Wong|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|[Griffiths, Thoma...|{Fri, 01 Aug 2025...|Griffiths|   Thomas L.|        v1|Fri, 01 Aug 2025 ...| Thomas L. Griffiths|\n",
      "|2508.10914|            cs|[[Collins, Kather...|[{Fri, 01 Aug 202...|Katherine Collins| 2025-08-18|[Tenenbaum, Joshu...|{Fri, 01 Aug 2025...|Tenenbaum|   Joshua B.|        v1|Fri, 01 Aug 2025 ...| Joshua B. Tenenbaum|\n",
      "|2508.00310|       physics|[[Zhang, Yong, ],...|[{Fri, 01 Aug 202...|    Xianfeng Chen| 2025-08-04|     [Zhang, Yong, ]|{Fri, 01 Aug 2025...|    Zhang|        Yong|        v1|Fri, 01 Aug 2025 ...|          Yong Zhang|\n",
      "|2508.00310|       physics|[[Zhang, Yong, ],...|[{Fri, 01 Aug 202...|    Xianfeng Chen| 2025-08-04|  [Chen, Xianfeng, ]|{Fri, 01 Aug 2025...|     Chen|    Xianfeng|        v1|Fri, 01 Aug 2025 ...|       Xianfeng Chen|\n",
      "+----------+--------------+--------------------+--------------------+-----------------+-----------+--------------------+--------------------+---------+------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_exploded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e5229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- final_category: string (nullable = false)\n",
      " |-- authors_parsed: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- versions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- created: string (nullable = true)\n",
      " |    |    |-- version: string (nullable = true)\n",
      " |-- submitter: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- version: struct (nullable = true)\n",
      " |    |-- created: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- version_no: string (nullable = true)\n",
      " |-- version_date: string (nullable = true)\n",
      " |-- author_name: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_exploded.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2a6117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "\n",
    "df_exploded = df_exploded.withColumn(\n",
    "    \"version_ts\",\n",
    "    to_timestamp(\"version_ts\", \"EEE, dd MMM yyyy HH:mm:ss z\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02503502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'final_category',\n",
       " 'authors_parsed',\n",
       " 'versions',\n",
       " 'submitter',\n",
       " 'update_date',\n",
       " 'author',\n",
       " 'version',\n",
       " 'last_name',\n",
       " 'first_name',\n",
       " 'version_no',\n",
       " 'version_date',\n",
       " 'author_name',\n",
       " 'version_ts']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f54eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded=df_exploded.drop(\"authors_parsed\",\"versions\",\"author\",\"version\",\"version_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7d004f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_exploded.coalesce(1).write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"../../../data/tableauProcessedCSV/arxiv_exploded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a504ed4",
   "metadata": {},
   "source": [
    "SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fa1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "TARGETS = {\n",
    "    \"cs\": 12000,\n",
    "    \"math\": 10000,\n",
    "    \"physics\": 8000,\n",
    "    \"engineering\": 7000,\n",
    "    \"stat\": 6000,\n",
    "    \"bio\": 6000,\n",
    "    \"econ\": 5000,\n",
    "    \"other\": 6000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b99c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_class(df, label, target, seed=42):\n",
    "    class_df = df.filter(col(\"final_category\") == label)\n",
    "    total = class_df.count()\n",
    "\n",
    "    if total <= target:\n",
    "        # Not enough samples → keep all\n",
    "        print(f\"[INFO] Keeping all {total} samples for class '{label}'\")\n",
    "        return class_df\n",
    "    else:\n",
    "        fraction = target / total\n",
    "        print(f\"[INFO] Sampling class '{label}': {target}/{total} (fraction={fraction:.4f})\")\n",
    "        return class_df.sample(\n",
    "            withReplacement=False,\n",
    "            fraction=fraction,\n",
    "            seed=seed\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8975293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling class 'cs': 12000/691231 (fraction=0.0174)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling class 'math': 10000/556370 (fraction=0.0180)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling class 'physics': 8000/201469 (fraction=0.0397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling class 'engineering': 7000/66850 (fraction=0.1047)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling class 'stat': 6000/58160 (fraction=0.1032)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling class 'bio': 6000/32717 (fraction=0.1834)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling class 'econ': 5000/10145 (fraction=0.4929)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:================================================>       (33 + 5) / 38]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sampling class 'other': 6000/1273390 (fraction=0.0047)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sampled_dfs = []\n",
    "\n",
    "for label, target in TARGETS.items():\n",
    "    sampled = sample_class(df, label, target)\n",
    "    sampled_dfs.append(sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464e00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "final_df = reduce(lambda d1, d2: d1.unionByName(d2), sampled_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37fd3d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=====================================================>(302 + 2) / 304]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|final_category|count|\n",
      "+--------------+-----+\n",
      "|cs            |12132|\n",
      "|math          |10082|\n",
      "|physics       |7987 |\n",
      "|engineering   |6991 |\n",
      "|other         |6114 |\n",
      "|bio           |5998 |\n",
      "|stat          |5903 |\n",
      "|econ          |4968 |\n",
      "+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "final_dist = (\n",
    "    final_df.groupBy(\"final_category\")\n",
    "    .agg(count(\"*\").alias(\"count\"))\n",
    "    .orderBy(col(\"count\").desc())\n",
    ")\n",
    "\n",
    "final_dist.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5b9d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_df = final_df.coalesce(8)\n",
    "\n",
    "final_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"../../../data/processed/arxiv_8class_60k.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e3f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+---------+-------------------+--------------------+-----------+--------------------+----------------+--------------+\n",
      "|            abstract|             authors|      authors_parsed|            comments|                 doi|       id|         journal-ref|             license|report-no|          submitter|               title|update_date|            versions|primary_category|final_category|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+---------+-------------------+--------------------+-----------+--------------------+----------------+--------------+\n",
      "|  We illustrate t...|Shenghui Su, and ...|[[Su, Shenghui, ]...|14 pages, and 2 t...|                NULL|0704.0492|                NULL|http://arxiv.org/...|     NULL|        Shenghui Su|Refuting the Pseu...| 2010-02-04|[{Wed, 4 Apr 2007...|           cs.CR|            cs|\n",
      "|  We introduce a ...|Le Song, Alex Smo...|[[Song, Le, ], [S...|             9 pages|                NULL|0704.2668|                NULL|                NULL|     NULL|       Alex Smola J|Supervised Featur...| 2007-05-23|[{Fri, 20 Apr 200...|           cs.LG|            cs|\n",
      "|  The low-snr cap...| Mustafa Cenk Gursoy|[[Gursoy, Mustafa...|To appear in the ...|10.1109/ISIT.2007...|0705.0124|                NULL|                NULL|     NULL|Mustafa Cenk Gursoy|On the Low-SNR Ca...| 2016-11-17|[{Tue, 1 May 2007...|           cs.IT|            cs|\n",
      "|  Optimal delay-t...|Lei Ying and R. S...|[[Ying, Lei, ], [...|            13 pages|                NULL|0705.0326|                NULL|                NULL|     NULL|           Lei Ying|Optimal Delay-Thr...| 2007-07-13|[{Wed, 2 May 2007...|           cs.NI|            cs|\n",
      "|  The multiobject...|Emilie Bouyer (IR...|[[Bouyer, Emilie,...|                NULL|                NULL|0705.0856|ASME Design Engin...|                NULL|     NULL|     Damien Chablat|The Multiobjectiv...| 2007-05-23|[{Mon, 7 May 2007...|           cs.RO|            cs|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+--------------------+---------+-------------------+--------------------+-----------+--------------------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.limit(5).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (System / PySpark)",
   "language": "python",
   "name": "spark-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
