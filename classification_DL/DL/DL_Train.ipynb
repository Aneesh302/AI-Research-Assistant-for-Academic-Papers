{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd943b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1f9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/home/sunbeam/STUDY_NEW/PROJECT/data/processed/arxiv_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39941663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39440 entries, 0 to 39439\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   abstract          39440 non-null  object\n",
      " 1   authors           39440 non-null  object\n",
      " 2   authors_parsed    39440 non-null  object\n",
      " 3   comments          24248 non-null  object\n",
      " 4   doi               8837 non-null   object\n",
      " 5   id                39440 non-null  object\n",
      " 6   journal-ref       7022 non-null   object\n",
      " 7   license           37340 non-null  object\n",
      " 8   report-no         821 non-null    object\n",
      " 9   submitter         39407 non-null  object\n",
      " 10  title             39440 non-null  object\n",
      " 11  update_date       39440 non-null  object\n",
      " 12  versions          39440 non-null  object\n",
      " 13  primary_category  39440 non-null  object\n",
      " 14  final_category    39440 non-null  object\n",
      "dtypes: object(15)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93883883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f556360",
   "metadata": {},
   "source": [
    "Only keep Required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4d7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"abstract\", \"final_category\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931fb53b",
   "metadata": {},
   "source": [
    "TEXT EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36d5c7",
   "metadata": {},
   "source": [
    "Abstract length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ded3cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39440.000000\n",
       "mean       144.144752\n",
       "std         61.989732\n",
       "min          5.000000\n",
       "50%        144.000000\n",
       "90%        228.000000\n",
       "95%        250.000000\n",
       "99%        281.000000\n",
       "max        567.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"length\"] = df[\"abstract\"].str.split().str.len()\n",
    "\n",
    "df[\"length\"].describe(percentiles=[0.5, 0.9, 0.95, 0.99])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad358c9",
   "metadata": {},
   "source": [
    "Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd811a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_category\n",
       "cs             0.428778\n",
       "math           0.342672\n",
       "physics        0.125203\n",
       "engineering    0.040948\n",
       "stat           0.035827\n",
       "bio            0.020360\n",
       "econ           0.006212\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"final_category\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b17e9",
   "metadata": {},
   "source": [
    "Vocabulary size estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ca0350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38753"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "tokens = []\n",
    "for t in df[\"abstract\"].head(5000):\n",
    "    tokens.extend(nltk.word_tokenize(t.lower()))\n",
    "\n",
    "vocab_size = len(set(tokens))\n",
    "vocab_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20582406",
   "metadata": {},
   "source": [
    "TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d986b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\$.*?\\$\", \" \", text)  # remove latex math\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "df[\"clean_abstract\"] = df[\"abstract\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23194da",
   "metadata": {},
   "source": [
    "LABEL ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "197b7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"final_category\"])\n",
    "num_classes = len(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee8db74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label_encoder_category.pkl\",\"wb\") as file:\n",
    "    pickle.dump(le,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea273477",
   "metadata": {},
   "source": [
    "TRAIN / TEST SPLIT (STRATIFIED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737a05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"clean_abstract\"],\n",
    "    df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9140de1",
   "metadata": {},
   "source": [
    "TOKENIZATION & PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2c4fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 12:00:54.853533: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-21 12:00:55.071291: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-21 12:00:56.525182: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_WORDS = 40000\n",
    "MAX_LEN = 150\n",
    "  # from EDA\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99958800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\",\"wb\") as file:\n",
    "    pickle.dump(tokenizer,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff43d51",
   "metadata": {},
   "source": [
    "EMBEDDING GLOVE LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a53af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "embedding_index = {}\n",
    "\n",
    "with open(\"/home/sunbeam/STUDY_NEW/PROJECT/data/embeddings/glove.6B.100d.txt\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embedding_index[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a186ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "vocab_size = min(MAX_WORDS, len(word_index)) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= vocab_size:\n",
    "        continue\n",
    "    vector = embedding_index.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4a1c641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010946105480698644\n",
      "0.4208363194609128\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(embedding_matrix))\n",
    "print(np.std(embedding_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d92503",
   "metadata": {},
   "source": [
    "BUILD BiLSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a9135d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunbeam/.local/share/mamba/envs/tf-gpu/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768971494.830720    5954 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=MAX_LEN,\n",
    "    trainable=False   # VERY important for GloVe\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50e9d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Bidirectional, LSTM, Dense, Dropout\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "    Bidirectional(LSTM(64,dropout=0.2)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecefaa0",
   "metadata": {},
   "source": [
    "HANDLE CLASS IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9863ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11879070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    \"fit\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    ")\n",
    "\n",
    "tensorboard_cb = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,     # weight histograms\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    update_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",        # watch validation loss\n",
    "    patience=6,                # stop after 3 epochs of no improvement\n",
    "    restore_best_weights=True  # rollback to best model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b99914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │     \u001b[38;5;34m4,000,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,000,100</span> (15.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,000,100\u001b[0m (15.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,000,100</span> (15.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,000,100\u001b[0m (15.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 10:31:09.428644: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.4048 - loss: 1.7336 - val_accuracy: 0.5633 - val_loss: 1.2805\n",
      "Epoch 2/8\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.4909 - loss: 1.4094 - val_accuracy: 0.5292 - val_loss: 1.1643\n",
      "Epoch 3/8\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5156 - loss: 1.2412 - val_accuracy: 0.6024 - val_loss: 1.0666\n",
      "Epoch 4/8\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5604 - loss: 1.1028 - val_accuracy: 0.6530 - val_loss: 0.9850\n",
      "Epoch 5/8\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5938 - loss: 1.0488 - val_accuracy: 0.6023 - val_loss: 0.9838\n",
      "Epoch 6/8\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.6113 - loss: 0.9779 - val_accuracy: 0.6016 - val_loss: 1.0159\n",
      "Epoch 7/8\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.6176 - loss: 0.9608 - val_accuracy: 0.6421 - val_loss: 0.9343\n",
      "Epoch 8/8\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.6436 - loss: 0.9014 - val_accuracy: 0.6961 - val_loss: 0.8501\n"
     ]
    }
   ],
   "source": [
    "embedding_layer.trainable = False\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=8,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop, tensorboard_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a62a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.6647 - loss: 0.8188 - val_accuracy: 0.6777 - val_loss: 0.8674\n",
      "Epoch 2/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.6743 - loss: 0.7803 - val_accuracy: 0.6943 - val_loss: 0.8356\n",
      "Epoch 3/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.6901 - loss: 0.7452 - val_accuracy: 0.6852 - val_loss: 0.8577\n",
      "Epoch 4/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6886 - loss: 0.7249 - val_accuracy: 0.7138 - val_loss: 0.8048\n",
      "Epoch 5/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7003 - loss: 0.6970 - val_accuracy: 0.7167 - val_loss: 0.7939\n",
      "Epoch 6/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7045 - loss: 0.6812 - val_accuracy: 0.7073 - val_loss: 0.8092\n",
      "Epoch 7/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7114 - loss: 0.6587 - val_accuracy: 0.7097 - val_loss: 0.8082\n",
      "Epoch 8/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7229 - loss: 0.6356 - val_accuracy: 0.7211 - val_loss: 0.7806\n",
      "Epoch 9/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7255 - loss: 0.6313 - val_accuracy: 0.7132 - val_loss: 0.8043\n",
      "Epoch 10/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7345 - loss: 0.5986 - val_accuracy: 0.7300 - val_loss: 0.7553\n",
      "Epoch 11/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7394 - loss: 0.5701 - val_accuracy: 0.7262 - val_loss: 0.7717\n",
      "Epoch 12/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7452 - loss: 0.5593 - val_accuracy: 0.7428 - val_loss: 0.7220\n",
      "Epoch 13/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7525 - loss: 0.5610 - val_accuracy: 0.7368 - val_loss: 0.7509\n",
      "Epoch 14/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7601 - loss: 0.5294 - val_accuracy: 0.7270 - val_loss: 0.7776\n",
      "Epoch 15/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7643 - loss: 0.5072 - val_accuracy: 0.7367 - val_loss: 0.7635\n",
      "Epoch 16/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7730 - loss: 0.4902 - val_accuracy: 0.7490 - val_loss: 0.7398\n",
      "Epoch 17/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7754 - loss: 0.4914 - val_accuracy: 0.7446 - val_loss: 0.7420\n",
      "Epoch 18/50\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7781 - loss: 0.4641 - val_accuracy: 0.7409 - val_loss: 0.7578\n"
     ]
    }
   ],
   "source": [
    "embedding_layer.trainable = True\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop,tensorboard_cb]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57f49c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7269846200942993, 0.736650288105011, 0.7490096688270569, 0.7445729970932007, 0.7409285306930542]\n",
      "[0.777579128742218, 0.7635042071342468, 0.7398005127906799, 0.7419564723968506, 0.7577699422836304]\n"
     ]
    }
   ],
   "source": [
    "print(history_phase2.history[\"val_accuracy\"][-5:])\n",
    "print(history_phase2.history[\"val_loss\"][-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32146361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7490096688270569\n",
      "0.7219878435134888\n"
     ]
    }
   ],
   "source": [
    "print(max(history_phase2.history[\"val_accuracy\"]))\n",
    "print(min(history_phase2.history[\"val_loss\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0fc7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/arxiv_bilstm_model.keras\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96812375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a relatively new topic in computability theory is the study of notions of computation that are robust against mistakes on some kind of small set however despite the recent popularity of this topic relatively foundational questions about the notions of reducibility involved still persist in this paper we examine two notions of robust information coding effective dense reducibility and coarse reducibility and answer the question posed in 1 whether the degrees of functions under these reductions are the same as the degrees of sets despite the surface similarity of these two reducibilities we show that every uniform coarse degree contains a set but that this fails even for the non uniform effective dense degrees we then further distinguish these two notions by showing that whether g is coarsely reducible to f is an arithmetic property of f and g while for non uniform effective dense reducibility it is a complete property to prove these results we introduce notions of forcing that allow us to build generic effective dense and coarse descriptions which may be of use in further exploration of these topics including the open questions we pose in the final section'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[16032]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2890e50c",
   "metadata": {},
   "source": [
    "TESTING OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "309e7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('/home/sunbeam/STUDY_NEW/PROJECT/src/Modelling/models/arxiv_bilstm_model.keras',compile=False)\n",
    "\n",
    "with open(\"/home/sunbeam/STUDY_NEW/PROJECT/src/Modelling/models/label_encoder_category.pkl\",\"rb\") as file:\n",
    "    label_encoder=pickle.load(file)\n",
    "\n",
    "with open(\"/home/sunbeam/STUDY_NEW/PROJECT/src/Modelling/models/tokenizer.pkl\",\"rb\") as file:\n",
    "    tokenizer=pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c31e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_test_clean = X_test.apply(clean_text)\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_clean)\n",
    "\n",
    "X_test_seq = pad_sequences(\n",
    "    X_test_seq,\n",
    "    maxlen=MAX_LEN,\n",
    "    padding=\"post\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32dd6f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/124\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 867ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-21 13:22:57.290244: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`axis` must be fewer than the number of dimensions (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_probs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# True labels\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Metrics\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, f1_score\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/tf-gpu/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/tf-gpu/lib/python3.10/site-packages/pandas/core/base.py:735\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03mReturn int position of the {value} value in the Series.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;124;03msince series is zero-indexed.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    734\u001b[0m delegate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m--> 735\u001b[0m \u001b[43mnv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_minmax_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m skipna \u001b[38;5;241m=\u001b[39m nv\u001b[38;5;241m.\u001b[39mvalidate_argmax_with_skipna(skipna, args, kwargs)\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delegate, ExtensionArray):\n",
      "File \u001b[0;32m~/.local/share/mamba/envs/tf-gpu/lib/python3.10/site-packages/pandas/compat/numpy/function.py:400\u001b[0m, in \u001b[0;36mvalidate_minmax_axis\u001b[0;34m(axis, ndim)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m ndim \u001b[38;5;129;01mor\u001b[39;00m (axis \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m+\u001b[39m axis \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`axis` must be fewer than the number of dimensions (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `axis` must be fewer than the number of dimensions (1)"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_probs = model.predict(X_test_seq, batch_size=64)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# True labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
    "print(\"Micro F1:\", f1_score(y_true, y_pred, average=\"micro\"))\n",
    "print(\"Weighted F1:\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=label_encoder.classes_\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
